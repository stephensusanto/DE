{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c416354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephensusanto/Desktop/Intro to Programming/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import mimetypes\n",
    "import numpy as np\n",
    "\n",
    "# plot\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# selenium method\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pyperclip\n",
    "import time\n",
    "\n",
    "# analysis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# duckdb\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db761c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c80fb14",
   "metadata": {},
   "source": [
    "##### Class Download File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdd4b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "class download_file:\n",
    "    def status_bar_api(self, api_url:str, csv_filename:str = None, status:str = 'api'):\n",
    "        # Stream the download\n",
    "        if status == 'api':\n",
    "            with requests.get(api_url, stream=True) as response:\n",
    "                response.raise_for_status()\n",
    "                total_size = int(response.headers.get('content-length', 0))\n",
    "                chunk_size = 1024 * 1024  # 1 MB chunks\n",
    "                \n",
    "                chunks = []\n",
    "                with tqdm(total=total_size, unit='B', unit_scale=True, desc='Downloading') as pbar:\n",
    "                    for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "                        if chunk:\n",
    "                            chunks.append(chunk)\n",
    "                            pbar.update(len(chunk))\n",
    "                \n",
    "                # Combine chunks into a single bytes object\n",
    "                content = b''.join(chunks)\n",
    "            \n",
    "            # Save CSV if filename is provided\n",
    "            if csv_filename:\n",
    "                with open(csv_filename, 'wb') as f:\n",
    "                    f.write(content)\n",
    "        else:\n",
    "            response = requests.get(api_url, stream=True)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Determine filename\n",
    "            if \"Content-Disposition\" in response.headers:\n",
    "                content_disposition = response.headers[\"Content-Disposition\"]\n",
    "                filename = content_disposition.split(\"filename=\")[-1].strip('\"')\n",
    "            else:\n",
    "                filename = os.path.basename(api_url)\n",
    "\n",
    "            # If filename has no extension, try to guess from Content-Type\n",
    "            if \".\" not in filename:\n",
    "                content_type = response.headers.get(\"Content-Type\", \"\")\n",
    "                extension = mimetypes.guess_extension(content_type.split(\";\")[0].strip())\n",
    "                if extension:\n",
    "                    filename += extension\n",
    "\n",
    "            # Get total file size for progress bar (in bytes)\n",
    "            total_size = int(response.headers.get(\"content-length\", 0))\n",
    "            chunk_size = 8192  # 8 KB per chunk\n",
    "\n",
    "            # Download with progress bar\n",
    "            with open(filename, \"wb\") as f, tqdm(\n",
    "                total=total_size, unit='B', unit_scale=True, desc=filename\n",
    "            ) as progress_bar:\n",
    "                for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                        progress_bar.update(len(chunk))\n",
    "                \n",
    "\n",
    "    # download from cer \n",
    "    def download_from_cer(self, url:str, csv_filename:str=None):\n",
    "        \"\"\"Extract API URL from CER datasets using Selenium and download CSV.\"\"\"\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "\n",
    "        # Find and click \"Copy API URL\" button\n",
    "        button = wait.until(\n",
    "            EC.element_to_be_clickable(\n",
    "                (By.XPATH, \"//button[.//span[contains(text(), 'Copy API URL')]]\")\n",
    "            )\n",
    "        )\n",
    "        button.click()\n",
    "        time.sleep(1)  # wait for clipboard update\n",
    "\n",
    "        api_url = pyperclip.paste()\n",
    "        driver.quit()\n",
    "\n",
    "        cer_code = url.split(\"/\")[-1]\n",
    "        api_url = f\"https://api.cer.gov.au/datahub-public/v1/api/Dataset/NGER/dataset/{cer_code}.csv\"\n",
    "        print(\"Downloading from:\", api_url)\n",
    "\n",
    "        csv_filename = f\"{cer_code}.csv\"\n",
    "        return self.status_bar_api(api_url=api_url, csv_filename=csv_filename)\n",
    "\n",
    "    def download_cer_markets(self, url:str):\n",
    "        url_header = url.split('/')[2]\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            # Step 2: Find the button/link with the XLSX file\n",
    "        div_tags = soup.find_all(\"div\", class_=\"cer-accordion__body__item\")\n",
    "        for div in div_tags:\n",
    "            a_tag = div.find(\"a\", href=True)\n",
    "            if a_tag:\n",
    "                text = a_tag.get_text(strip=True).lower()  # normalize text\n",
    "                if \"csv\" in text:\n",
    "                    file_href = a_tag[\"href\"]\n",
    "                    full_url = f\"https://www.{url_header}{file_href}\"\n",
    "                    #print(full_url)\n",
    "                    self.status_bar_api(api_url=full_url,csv_filename=None, status='file')\n",
    "    \n",
    "    def download_abs(self, url:str):\n",
    "        url_header = url.split('/')[2]\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        # Find the link for \"Population and people\"\n",
    "        target_div = None\n",
    "        for div in soup.find_all(\"div\", class_=\"file-description-link-formatter\"):\n",
    "            h4 = div.find(\"h4\")\n",
    "            if h4 and \"Economy and industry\" in h4.text:\n",
    "                target_div = div\n",
    "                break\n",
    "        if target_div:\n",
    "            a_tag = target_div.find(\"a\", href=True)\n",
    "            relative_url = a_tag['href']\n",
    "            download_url = f\"https://{url_header}\" + relative_url\n",
    "            print(\"Found download URL:\", download_url)\n",
    "            self.status_bar_api(api_url=download_url,csv_filename=None, status='file')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513799fb",
   "metadata": {},
   "source": [
    "<h1>Retrieve Data Set </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f48d9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Download First Dataset ....\n",
      "Downloading from: https://api.cer.gov.au/datahub-public/v1/api/Dataset/NGER/dataset/ID0243.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 83.3k/83.3k [00:00<00:00, 69.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Download Second Dataset ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "total-lgcs-and-capacity-accredited-power-stations-2025.csv: 100%|██████████| 421/421 [00:00<00:00, 2.32MB/s]\n",
      "power-stations-and-projects-accredited.csv: 100%|██████████| 25.8k/25.8k [00:00<00:00, 33.5MB/s]\n",
      "power-stations-and-projects-committed.csv: 100%|██████████| 1.89k/1.89k [00:00<00:00, 8.06MB/s]\n",
      "power-stations-and-projects-probable.csv: 100%|██████████| 2.22k/2.22k [00:00<00:00, 4.88MB/s]\n",
      "total-lgcs-rec-registry-0.csv: 100%|██████████| 45.4k/45.4k [00:00<00:00, 10.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Download Third Dataset ....\n",
      "Found download URL: https://www.abs.gov.au/methodologies/data-region-methodology/2011-24/14100DO0003_2011-24.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14100DO0003_2011-24.xlsx: 100%|██████████| 19.7M/19.7M [00:03<00:00, 6.20MB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "download = download_file()\n",
    "\n",
    "# first dataset\n",
    "print(\"Processing Download First Dataset ....\")\n",
    "cer_url = \"https://data.cer.gov.au/datasets/NGER/ID0243\"\n",
    "download.download_from_cer(url=cer_url)\n",
    "# # second dataset\n",
    "print(\"Processing Download Second Dataset ....\")\n",
    "cer_markets_url = \"https://cer.gov.au/markets/reports-and-data/large-scale-renewable-energy-data\"\n",
    "download.download_cer_markets(url=cer_markets_url)\n",
    "# third dataset\n",
    "print(\"Processing Download Third Dataset ....\")\n",
    "abs_url = \"https://www.abs.gov.au/methodologies/data-region-methodology/2011-24#data-downloads\"\n",
    "download.download_abs(url=abs_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469afbad",
   "metadata": {},
   "source": [
    "<h1>Data Integration and Cleaning Data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d92d2a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cleaningData:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def show_null_data(self, data:pd.DataFrame):\n",
    "        '''\n",
    "            Showing Null Data for each column in a single dataframe\n",
    "\n",
    "            Args:\n",
    "                data: Dataframe to analyze\n",
    "\n",
    "        '''\n",
    "        null_count = data.isna().sum()\n",
    "        null_percent = data.isna().sum() / len(data)\n",
    "        null_percent = null_percent.apply(lambda x: f\"{x:.1%}\")\n",
    "        print(\"Total Duplicated Count: \", data.duplicated().sum())\n",
    "        results = pd.concat([null_count, null_percent], axis=1)\n",
    "        results.columns = ['Null Total Count', 'Null Percentage']\n",
    "        return results\n",
    "    \n",
    "    def split_categorical_numerical(self, data:pd.DataFrame):\n",
    "        numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "        categorical_cols = data.select_dtypes(include=['object', 'category']).columns\n",
    "        \n",
    "        return numerical_cols, categorical_cols\n",
    "\n",
    "class connectDB:\n",
    "    def __init__(self):\n",
    "        self.connection =  duckdb.connect('my_database.duckdb') \n",
    "    \n",
    "    def create_new_table(self, df:pd.DataFrame, table_name:str):\n",
    "        '''\n",
    "            Creating New Table Based on Dataframe Columns\n",
    "\n",
    "\n",
    "            Args:\n",
    "                1. df: Dataframe or that we want to convert into database\n",
    "                2. table_name: the name of the table that we want to create in duck db\n",
    "        '''\n",
    "        try:\n",
    "            con = self.connection\n",
    "            sql_types = {\n",
    "                'object': 'VARCHAR',\n",
    "                'int64': 'INTEGER',\n",
    "                'float64': 'DOUBLE',\n",
    "                'bool': 'BOOLEAN',\n",
    "                'datetime64[ns]': 'TIMESTAMP'\n",
    "            }\n",
    "\n",
    "            columns_sql = []\n",
    "            for col_name, dtype in df.dtypes.items():\n",
    "                sql_type = sql_types.get(str(dtype), 'VARCHAR')  # Default to VARCHAR\n",
    "                col_sql = f'\"{col_name}\" {sql_type}'\n",
    "                columns_sql.append(col_sql)\n",
    "\n",
    "            columns_str = \",\\n    \".join(columns_sql)\n",
    "            create_table_sql = f\"CREATE TABLE {table_name} (\\n    {columns_str}\\n);\"\n",
    "            con.execute(create_table_sql)\n",
    "            con.close()\n",
    "        except Exception as err:\n",
    "            con.close()\n",
    "            print(err)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def insert_data(self, df:pd.DataFrame, table_name: str, column_map: dict):\n",
    "        '''\n",
    "        Inserting database different column name with the csv\n",
    "\n",
    "        Args:\n",
    "            df: Dataframe to insert\n",
    "            table_name: Name of the existing DuckDB table\n",
    "            column_map: Mapping from dataframe columns to table columns\n",
    "        \n",
    "        column_map = {'df_col1': 'table_colA', 'df_col2': 'table_colB'}\n",
    "        '''\n",
    "        try:\n",
    "            con = self.connection\n",
    "\n",
    "            # Prepare SELECT clause using mapping\n",
    "            select_clause = \", \".join([f'\"{df_col}\" AS \"{table_col}\"' for df_col, table_col in column_map.items()])\n",
    "            \n",
    "            # Register DataFrame as a relation\n",
    "            con.register(\"df_temp\", df)\n",
    "            \n",
    "            # Build INSERT SQL\n",
    "            sql = f\"\"\"\n",
    "            INSERT INTO {table_name} ({', '.join(column_map.values())})\n",
    "            SELECT {select_clause} FROM df_temp\n",
    "            \"\"\"\n",
    "            con.execute(sql)\n",
    "            con.close()\n",
    "        except Exception as err:\n",
    "            con.close()\n",
    "            print(err)\n",
    "        \n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6151a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# first url file\n",
    "df_nger = pd.read_csv(\"ID0243.csv\")\n",
    "\n",
    "# second url file\n",
    "df_cer_1_approved = pd.read_csv(\"power-stations-and-projects-accredited.csv\")\n",
    "df_cer_1_commited = pd.read_csv(\"power-stations-and-projects-committed.csv\")\n",
    "df_cer_1_probable = pd.read_csv(\"power-stations-and-projects-probable.csv\")\n",
    "\n",
    "\n",
    "# third url file\n",
    "df_abs = pd.ExcelFile(\"14100DO0003_2011-24.xlsx\")\n",
    "statistical_area = pd.read_excel(df_abs, 'Table 1', header=[5,6])\n",
    "lga_area = pd.read_excel(df_abs, 'Table 2', header=[5,6])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d12e21",
   "metadata": {},
   "source": [
    "#### Cleaning the NGER.CSV dataset and put it into DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13b26fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Duplicated Count:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2h/b49chrcn56z4tf_5y0zw27740000gn/T/ipykernel_86945/1614917072.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_nger_cleaning.fillna(\"Unknown\", inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null Total Count</th>\n",
       "      <th>Null Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Reporting entity</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Facility name</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electricity production MWh</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total scope 1 emissions t CO2 e</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total scope 2 emissions t CO2 e</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emission intensity t CO2 e MWh</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grid connected</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grid</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Primary fuel</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Important notes</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Null Total Count Null Percentage\n",
       "Reporting entity                                0            0.0%\n",
       "Facility name                                   0            0.0%\n",
       "Type                                            0            0.0%\n",
       "State                                           0            0.0%\n",
       "Electricity production MWh                      0            0.0%\n",
       "Total scope 1 emissions t CO2 e                 0            0.0%\n",
       "Total scope 2 emissions t CO2 e                 0            0.0%\n",
       "Emission intensity t CO2 e MWh                  0            0.0%\n",
       "Grid connected                                  0            0.0%\n",
       "Grid                                            0            0.0%\n",
       "Primary fuel                                    0            0.0%\n",
       "Important notes                                 0            0.0%"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# module for Cleaning Data\n",
    "cleaning_data = cleaningData()\n",
    "\n",
    "\n",
    "df_nger_numerical, df_nger_categorical = cleaning_data.split_categorical_numerical(df_nger) \n",
    "df_nger.replace('-', np.nan, inplace=True)\n",
    "\n",
    "df_nger_cleaning = df_nger.drop(columns=['Electricity production GJ', 'Total emissions t CO2 e'])\n",
    "df_nger_cleaning.fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "cleaning_data.show_null_data(df_nger_cleaning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c87b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Duplicated Count:  0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 280 entries, 0 to 279\n",
      "Data columns (total 8 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Accreditation code        280 non-null    object \n",
      " 1   Power station name        280 non-null    object \n",
      " 2   State                     280 non-null    object \n",
      " 3   Postcode                  280 non-null    int64  \n",
      " 4   Installed capacity (MW)   280 non-null    float64\n",
      " 5   Fuel Source (s)           280 non-null    object \n",
      " 6   Accreditation start date  280 non-null    object \n",
      " 7   Approval date             280 non-null    object \n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 17.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_cer_1_approved.replace('-', np.nan, inplace=True)\n",
    "\n",
    "df_cer_1_approved\n",
    "cleaning_data.show_null_data(df_cer_1_approved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b431d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Duplicated Count:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null Total Count</th>\n",
       "      <th>Null Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Project Name</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MW Capacity</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fuel Source</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Committed Date (Month/Year)</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Null Total Count Null Percentage\n",
       "Project Name                                0            0.0%\n",
       "State                                       0            0.0%\n",
       "MW Capacity                                 0            0.0%\n",
       "Fuel Source                                 0            0.0%\n",
       "Committed Date (Month/Year)                 0            0.0%"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cer_1_commited.replace('-', np.nan, inplace=True)\n",
    "\n",
    "cleaning_data.show_null_data(df_cer_1_commited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "038caa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Duplicated Count:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null Total Count</th>\n",
       "      <th>Null Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Project Name</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MW Capacity</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fuel Source</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Null Total Count Null Percentage\n",
       "Project Name                 0            0.0%\n",
       "State                        0            0.0%\n",
       "MW Capacity                  0            0.0%\n",
       "Fuel Source                  0            0.0%"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cer_1_probable.replace('-', np.nan, inplace=True)\n",
    "cleaning_data.show_null_data(df_cer_1_probable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8909ebea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2f5b3c6",
   "metadata": {},
   "source": [
    "#### Process Creating Schema in Duck DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "690b1d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module related for database\n",
    "database = connectDB()\n",
    "\n",
    "column_name_facility = ['id','reporting_entity','facility_name','type','state',\n",
    "                        'electricity_production_mwh','scope_1_emission', \n",
    "                        'scope_2_emission','emission_intesity_mwh','grid_connected',\n",
    "                        'grid','primary_fuel', 'important_notes']\n",
    "\n",
    "column_names_power_stations = ['id', 'accreditation_code', 'power_station_name','state','postcode',\n",
    "                               'capacity_mw','source', 'accreditation_start_date','approval_date','commited_date','status']\n",
    "\n",
    "# Create an empty DataFrame with the specified columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "387a3f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"----------\")\n",
    "df_cer_1_approved.replace('-', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e96a41ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------\")\n",
    "#show_null_data(df_cer_1_commited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6facd105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------\")\n",
    "#show_null_data(df_cer_1_probable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8d483bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------\")\n",
    "#show_null_data(df_cer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eabecb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_null_data(df_cer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f11585e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"----------\")\n",
    "#show_null_data(statistical_area)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bea0c1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------\")\n",
    "#show_null_data(lga_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050c06dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
