{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9c416354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # progress bar\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import mimetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "cdd4b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------- Function List ----------------------------------------\n",
    "# 1 Status Bar to know the download progress bar\n",
    "def status_bar_api(api_url, csv_filename):\n",
    "    # Stream the download\n",
    "    with requests.get(api_url, stream=True) as response:\n",
    "        response.raise_for_status()\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        chunk_size = 1024 * 1024  # 1 MB chunks\n",
    "        \n",
    "        chunks = []\n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True, desc='Downloading') as pbar:\n",
    "            for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "                if chunk:\n",
    "                    chunks.append(chunk)\n",
    "                    pbar.update(len(chunk))\n",
    "        \n",
    "        # Combine chunks into a single bytes object\n",
    "        content = b''.join(chunks)\n",
    "    \n",
    "    # Save CSV if filename is provided\n",
    "    if csv_filename:\n",
    "        with open(csv_filename, 'wb') as f:\n",
    "            f.write(content)\n",
    "\n",
    "def download_file(url):\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Determine filename\n",
    "    if \"Content-Disposition\" in response.headers:\n",
    "        content_disposition = response.headers[\"Content-Disposition\"]\n",
    "        filename = content_disposition.split(\"filename=\")[-1].strip('\"')\n",
    "    else:\n",
    "        filename = os.path.basename(url)\n",
    "\n",
    "    # If filename has no extension, try to guess from Content-Type\n",
    "    if \".\" not in filename:\n",
    "        content_type = response.headers.get(\"Content-Type\", \"\")\n",
    "        extension = mimetypes.guess_extension(content_type.split(\";\")[0].strip())\n",
    "        if extension:\n",
    "            filename += extension\n",
    "\n",
    "    # Get total file size for progress bar (in bytes)\n",
    "    total_size = int(response.headers.get(\"content-length\", 0))\n",
    "    chunk_size = 8192  # 8 KB per chunk\n",
    "\n",
    "    # Download with progress bar\n",
    "    with open(filename, \"wb\") as f, tqdm(\n",
    "        total=total_size, unit='B', unit_scale=True, desc=filename\n",
    "    ) as progress_bar:\n",
    "        for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                progress_bar.update(len(chunk))\n",
    "    \n",
    "# Download from cer datasets\n",
    "def download_from_cer(url, csv_filename=None):\n",
    "    cer_code = url.split('/')[-1]\n",
    "    api_url = f\"https://api.cer.gov.au/datahub-public/v1/api/Dataset/NGER/dataset/{cer_code}.csv\"\n",
    "    print(\"downloading from:\" + api_url)\n",
    "    csv_filename = f\"{cer_code}.csv\"\n",
    "    # Stream the download\n",
    "    status_bar_api(api_url=api_url, csv_filename=csv_filename)\n",
    "\n",
    "def download_cer_markets(url):\n",
    "    url_header = url.split('/')[2]\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        # Step 2: Find the button/link with the XLSX file\n",
    "    div_tags = soup.find_all(\"div\", class_=\"cer-accordion__body__item\")\n",
    "    for div in div_tags:\n",
    "        a_tag = div.find(\"a\", href=True)\n",
    "        if \"XLSX\" in a_tag.get_text(strip=True): \n",
    "            download_href = a_tag[\"href\"]\n",
    "            download_url = f\"https://www.{url_header}\" + download_href\n",
    "            download_file(download_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7f48d9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading from:https://api.cer.gov.au/datahub-public/v1/api/Dataset/NGER/dataset/ID0243.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 83.3k/83.3k [00:00<00:00, 1.24MB/s]\n",
      "total-lgcs-and-capacity-accredited-power-stations-2025-0.xlsx: 100%|██████████| 12.3k/12.3k [00:00<00:00, 20.6MB/s]\n",
      "power-stations-and-projects-status.xlsx: 100%|██████████| 41.3k/41.3k [00:00<00:00, 3.40MB/s]\n",
      "power-stations-and-projects-status.xlsx: 100%|██████████| 41.3k/41.3k [00:00<00:00, 3.16MB/s]\n",
      "power-stations-and-projects-status.xlsx: 100%|██████████| 41.3k/41.3k [00:00<00:00, 3.12MB/s]\n",
      "total-lgcs-rec-registry.xlsx: 100%|██████████| 50.7k/50.7k [00:00<00:00, 3.51MB/s]\n"
     ]
    }
   ],
   "source": [
    "# first dataset\n",
    "cer_url = \"https://data.cer.gov.au/datasets/NGER/ID0243\"\n",
    "download_from_cer(cer_url)\n",
    "# second dataset\n",
    "cer_markets_url = \"https://cer.gov.au/markets/reports-and-data/large-scale-renewable-energy-data\"\n",
    "download_cer_markets(url=cer_markets_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
